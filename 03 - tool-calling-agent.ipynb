{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Part 3: Tool calling agent\n",
    "\n",
    "In this final part of the workshop, we will let our LLM roam free! We'll build a tool calling agent that can search the web, read webpages and answer up to date information about any question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tool-calling-agent](./assets/tool_calling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "\n",
    "import inspect\n",
    "from diskcache import Cache\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from typing import Any\n",
    "import jupyter_black\n",
    "import requests\n",
    "from markdownify import markdownify as md\n",
    "from dotenv import load_dotenv\n",
    "from googlesearch import search\n",
    "\n",
    "load_dotenv(dotenv_path=\".envrc\")\n",
    "\n",
    "jupyter_black.load()\n",
    "\n",
    "DEEPSEEK_API_KEY = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL = \"deepseek-chat\"\n",
    "cache = Cache(\"./cache\")\n",
    "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_openai_tool(func: callable) -> dict[str, Any]:\n",
    "    sig = inspect.signature(func)\n",
    "    if sig.parameters:\n",
    "        param = next(iter(sig.parameters.values()))\n",
    "        param_type = param.annotation\n",
    "        schema = param_type.model_json_schema()\n",
    "    else:\n",
    "        param_type = None\n",
    "        schema = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": (param_type.__doc__ if param_type else func.__doc__ or \"\"),\n",
    "            \"parameters\": schema,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "@cache.memoize(expire=3600)\n",
    "def llm_call(\n",
    "    messages: list[dict[str, str]], tools: list[dict[str, Any]], model: str\n",
    ") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools if tools else None,\n",
    "        temperature=0.0,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    if hasattr(message, \"reasoning_content\"):\n",
    "        del message.reasoning_content\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchWeb(BaseModel):\n",
    "    \"\"\"Search the web for a given query.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    max_results: int = 10\n",
    "\n",
    "\n",
    "# def search_web(data: SearchWeb) -> str:\n",
    "#     base_url = \"https://api.marginalia.nu/{key}/search/{query}\"\n",
    "#     url = base_url.format(key=\"public\", query=data.query)\n",
    "#     url += f\"?count={data.max_results}\"\n",
    "\n",
    "#     rsp = httpx.get(url)\n",
    "#     rsp.raise_for_status()\n",
    "\n",
    "#     results = rsp.json()[\"results\"]\n",
    "#     return str(results)\n",
    "\n",
    "\n",
    "def search_web(data: SearchWeb) -> str:\n",
    "    results = \"\"\n",
    "    for result in search(data.query, num_results=data.max_results, advanced=True):\n",
    "        results += f\"Title: {result.title}\\nDescription: {result.description}\\nURL: {result.url}\\n\\n\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "class ReadWebsite(BaseModel):\n",
    "    \"\"\"Read the content of a website and return it as text. (useful for further research)\"\"\"\n",
    "\n",
    "    url: str\n",
    "\n",
    "\n",
    "def read_website(data: ReadWebsite) -> str:\n",
    "\n",
    "    html_content = requests.get(data.url).text\n",
    "    return md(html_content)\n",
    "\n",
    "\n",
    "TOOLS = [\n",
    "    to_openai_tool(search_web),\n",
    "    to_openai_tool(read_website),\n",
    "]\n",
    "FUNC_TYPES = {\n",
    "    search_web: SearchWeb,\n",
    "    read_website: ReadWebsite,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'search_web',\n",
       "   'description': 'Search the web for a given query.',\n",
       "   'parameters': {'description': 'Search the web for a given query.',\n",
       "    'properties': {'query': {'title': 'Query', 'type': 'string'},\n",
       "     'max_results': {'default': 10,\n",
       "      'title': 'Max Results',\n",
       "      'type': 'integer'}},\n",
       "    'required': ['query'],\n",
       "    'title': 'SearchWeb',\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'read_website',\n",
       "   'description': 'Read the content of a website and return it as text. (useful for further research)',\n",
       "   'parameters': {'description': 'Read the content of a website and return it as text. (useful for further research)',\n",
       "    'properties': {'url': {'title': 'Url', 'type': 'string'}},\n",
       "    'required': ['url'],\n",
       "    'title': 'ReadWebsite',\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Paris - Wikipedia\n",
      "Description:  Paris is the fourth-most populous city in the European Union and the 30th most densely populated city in the world in 2022. \n",
      "URL: https://en.wikipedia.org/wiki/Paris\n",
      "\n",
      "Title: Paris - Wikipedia, den frie encyklopædi\n",
      "Description:  Paris er Frankrigs hovedstad og ligger ved Seinen i det nordlige Frankrig, i hjertet af regionen Île-de-France. Paris har en anslået befolkning på 2.2 mio. ( ... \n",
      "URL: https://da.wikipedia.org/wiki/Paris\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(search_web(SearchWeb(query=\"Paris\", max_results=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest news, sport and opinion from the Guardian                                                ![](https://sb.scorecardresearch.com/p?c1=2&c2=6035250&cv=2.0&cj=1&cs_ucfr=0&comscorekw=europe)   [Skip to main content](#maincontent)[Skip to navigation](#navigation)  [Print subscriptions](https://support.theguardian.com/subscribe/weekly?REFPVID=undefined&INTCMP=undefined&acquisitionData=%7B%22source%22%3A%22GUARDIAN_WEB%22%2C%22componentId%22%3A%22PrintSubscriptionsHeaderLink%22%2C%22componentType%...\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    read_website(data=ReadWebsite(url=\"https://www.theguardian.com/europe\")).replace(\n",
    "        \"\\n\", \" \"\n",
    "    )[:500]\n",
    "    + \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str,\n",
    "        system: str,\n",
    "        tools: list[dict[str, Any]] | None = None,\n",
    "        max_iters: int = 10,\n",
    "        func_types: dict[str, BaseModel] | None = None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tools = tools or []\n",
    "        self.messages: list[dict[str, str]] = []\n",
    "        self.func_types = func_types or {}\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "        self.max_iters = max_iters\n",
    "\n",
    "    def __call__(self, content: str, verbose: bool) -> str:\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        iterations = 0\n",
    "        while True:\n",
    "            iterations += 1\n",
    "            message = self._send()\n",
    "            self.messages.append(message)\n",
    "\n",
    "            tool_calls = getattr(message, \"tool_calls\", None)\n",
    "            if not tool_calls:\n",
    "                return message.content\n",
    "\n",
    "            for call in tool_calls:\n",
    "                func = globals()[call.function.name]\n",
    "                args_model = self.func_types[func]\n",
    "                args = (\n",
    "                    args_model.model_validate_json(call.function.arguments)\n",
    "                    if call.function.arguments != \"{}\"\n",
    "                    else None\n",
    "                )\n",
    "                print(f\"** CALLING FUNCTION {func.__name__} **\")\n",
    "                print(f\"*** ARGS ***\\n{args}\\n\")\n",
    "\n",
    "                result = func(args) if args else func()\n",
    "\n",
    "                if verbose is True:\n",
    "                    print(f\"*** RESULT ***\\n{result[:100]}...\\n***\")\n",
    "\n",
    "                self.messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": call.id,\n",
    "                        \"content\": result,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if iterations >= self.max_iters:\n",
    "                raise Exception(\"Max iterations reached\")\n",
    "\n",
    "    def _send(self):\n",
    "        return llm_call(self.messages, self.tools, self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** CALLING FUNCTION search_web **\n",
      "*** ARGS ***\n",
      "query='best performing Portuguese cyclist 2025 Tour de France' max_results=5\n",
      "\n",
      "*** RESULT ***\n",
      "Title: 2025 Tour de France: Ten Pro Cyclists Who Could Make History\n",
      "Description:  8 Jul 2025  ·  And...\n",
      "***\n",
      "** CALLING FUNCTION read_website **\n",
      "*** ARGS ***\n",
      "url='https://www.france24.com/en/sport/20250704-tour-de-france-2025-the-top-14-riders-cycling-vingegaard-pogacar-evenepoel'\n",
      "\n",
      "*** RESULT ***\n",
      "Access denied\n",
      "=============\n",
      "\n",
      "You don't have permission to access the page you requested.\n",
      "\n",
      "**What is ...\n",
      "***\n",
      "** CALLING FUNCTION read_website **\n",
      "*** ARGS ***\n",
      "url='https://cyclinguptodate.com/cycling/analysis-joao-almeidas-2025-season-a-year-of-transformation-and-triumph'\n",
      "\n",
      "*** RESULT ***\n",
      "ANALYSIS: João Almeida's 2025 Season - A year of transformation and triumph\n",
      "\n",
      "[![](https://r.testifie...\n",
      "***\n",
      "** CALLING FUNCTION read_website **\n",
      "*** ARGS ***\n",
      "url='https://www.bicycling.com/tour-de-france/a65267789/2025-tour-de-france-riders-watch/'\n",
      "\n",
      "*** RESULT ***\n",
      "2025 Tour de France: Ten Pro Cyclists Who Could Make History\n",
      "\n",
      "[![Search](/_assets/design-tokens/fre/...\n",
      "***\n",
      "Response: Based on the search results and the content read, the best-performing Portuguese cyclist in the 2025 Tour de France appears to be **João Almeida**. \n",
      "\n",
      "### Key Points:\n",
      "1. **Performance in 2024**: João Almeida finished fourth in the 2024 Tour de France, which was the second-best performance ever by a Portuguese rider in the event.\n",
      "2. **2025 Season**: He has had a dominant 2025 season, winning multiple stage races like the Tour de Suisse, Tour de Romandie, and Itzulia Basque Country, showcasing his strong form.\n",
      "3. **Tour de France 2025**: He is mentioned as a key teammate for Tadej Pogačar (UAE Team Emirates) and is expected to contend for a podium finish himself.\n",
      "\n",
      "João Almeida is the standout Portuguese cyclist in the 2025 Tour de France.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant who can answer multistep questions by sequentially calling functions. \n",
    "\n",
    "Follow a pattern of:\n",
    "- THOUGHT (reason step-by-step about which function to call next)\n",
    "- ACTION (call a function as a next step towards the final answer) \n",
    "- OBSERVATION (output of the function)\n",
    "\n",
    "Reason step by step which actions to take to get to the answer. \n",
    "\n",
    "Only call functions with arguments coming verbatim from the user or the output of other functions.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who was the best performing portuguese cyclist in the 2025 Tour de France?\"\n",
    "\n",
    "\n",
    "bot = Agent(\n",
    "    system=system_prompt, tools=TOOLS, func_types=FUNC_TYPES, model=\"deepseek-chat\"\n",
    ")\n",
    "response = bot(question, verbose=True)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise**\n",
    "\n",
    "\n",
    "- Build an agent that can answer the question: `What fell from the strange captain’s hand into the sea when he first tried to respond to Ahab’s hail?`\n",
    "- Use the [markitdown](https://github.com/microsoft/markitdown) library and the [bm25](https://pypi.org/project/rank-bm25/) to build a tool for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** CALLING FUNCTION search_book **\n",
      "*** ARGS ***\n",
      "query=\"Moby-Dick strange captain's hand fell into the sea Ahab's hail\" total_results=1\n",
      "\n",
      "*** RESULT ***\n",
      "An apple....\n",
      "***\n",
      "Response: The object that fell from the strange captain’s hand into the sea when he first tried to respond to Ahab’s hail was an apple.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant who can answer multistep questions by sequentially calling functions. \n",
    "\n",
    "Follow a pattern of:\n",
    "- THOUGHT (reason step-by-step about which function to call next)\n",
    "- ACTION (call a function as a next step towards the final answer) \n",
    "- OBSERVATION (output of the function)\n",
    "\n",
    "Reason step by step which actions to take to get to the answer. \n",
    "\n",
    "Only call functions with arguments coming verbatim from the user or the output of other functions.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What fell from the strange captain’s hand into the sea when he first tried to respond to Ahab’s hail?\"\n",
    "\n",
    "\n",
    "class SearchBook(BaseModel):\n",
    "    query: str\n",
    "    total_results: int = 10\n",
    "\n",
    "\n",
    "def search_book(data: SearchBook) -> str:\n",
    "    # Tips:\n",
    "    # Load the book into a string, split it into chunks, and use the bm25 library to search the chunks...\n",
    "    return \"An apple.\"  # this is obviously wrong :)\n",
    "\n",
    "\n",
    "TOOLS = [\n",
    "    to_openai_tool(search_book),\n",
    "]\n",
    "FUNC_TYPES = {\n",
    "    search_book: SearchBook,\n",
    "}\n",
    "\n",
    "\n",
    "bot = Agent(\n",
    "    system=system_prompt, tools=TOOLS, func_types=FUNC_TYPES, model=\"deepseek-chat\"\n",
    ")\n",
    "response = bot(question, verbose=True)\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
